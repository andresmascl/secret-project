# Scrap AI Bot

Voice-controlled computer automation using Claude's Computer Use API. Control your computer naturally through voice commands powered by AI vision and reasoning.

![License](https://img.shields.io/badge/license-AGPL--3.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Status](https://img.shields.io/badge/status-alpha-orange.svg)

## What is Scrap AI Bot?

Scrap AI Bot adds voice control to [Anthropic's Computer Use Demo](https://github.com/anthropics/claude-quickstarts/tree/main/computer-use-demo), enabling hands-free computer automation through natural language.

**Say "Ok Computer"** â†’ Speak your command â†’ Watch AI execute it

### Example Commands

- "Ok Computer, open Firefox and search for Python tutorials"
- "Ok Computer, create a new text document with today's date"
- "Ok Computer, take a screenshot and save it to desktop"
- "Ok Computer, organize my downloads folder by file type"

## How It Works

```
[Wake Word: "Ok Computer"]
    â†“
[Audio Capture]
    â†“
[Speech-to-Text (Whisper)]
    â†“
[Claude Computer Use API]
    â”œâ”€â”€ Takes screenshots
    â”œâ”€â”€ Reasons about actions
    â”œâ”€â”€ Controls mouse/keyboard
    â””â”€â”€ Executes multi-step tasks
    â†“
[Task Complete]
```

## Features

- ğŸ¤ **Wake word activation** - "Ok Computer" triggers listening
- ğŸ—£ï¸ **Natural language** - Speak commands like you would to a person
- ğŸ‘ï¸ **Visual understanding** - Claude sees your screen and reasons about it
- ğŸ–±ï¸ **Full computer control** - Mouse, keyboard, and bash commands
- ğŸ”„ **Multi-step execution** - Handles complex tasks automatically
- ğŸ³ **Dockerized** - Runs in safe, isolated environment
- ğŸ”’ **Privacy-focused** - Only audio after wake word is processed

## Quick Start

### Prerequisites

- Ubuntu 20.04+ or Debian 11+ (64-bit)
- Docker and Docker Compose
- Microphone
- Display
- API Keys:
  - [Anthropic API key](https://console.anthropic.com/) (Claude)
  - [OpenAI API key](https://platform.openai.com/) (Whisper)
  - [Picovoice Access Key](https://console.picovoice.ai/) (Wake word)

### Installation

```bash
# Clone the repository
git clone git@github.com:andresmascl/scrapbot.ai.git
cd scrap-ai-bot

# Run the installation script (handles everything)
chmod +x scripts/*.sh
./scripts/install.sh

# Configure API keys
nano .env  # Add your API keys (ANTHROPIC_API_KEY, OPENAI_API_KEY, PICOVOICE_ACCESS_KEY)
```

### First Run

```bash
# Start the service
./scripts/start.sh

# Access the interface
# VNC viewer: localhost:5900
# Web interface: http://localhost:6080

# Stop the service
./scripts/stop.sh
```

Say **"Ok Computer"** followed by your command. The system will:
1. Capture your voice
2. Transcribe to text
3. Send to Claude with screenshot
4. Execute actions visually
5. Return to listening

## Project Structure

```
scrap-ai-bot/
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ ARCHITECTURE.md                 # Technical architecture
â”œâ”€â”€ AI_INSTRUCTIONS.md              # Instructions for AI assistants
â”œâ”€â”€ CONTRIBUTING.md                 # Contribution guidelines
â”œâ”€â”€ CHANGELOG.md                    # Version history
â”œâ”€â”€ LICENSE                         # AGPL-3.0 license
â”œâ”€â”€ .env.example                    # Environment variables template
â”œâ”€â”€ .gitignore                      # Git ignore patterns
â”œâ”€â”€ .gitmodules                     # Git submodule configuration
â”‚
â”œâ”€â”€ computer-use-demo/              # Anthropic's demo (submodule)
â”‚   â””â”€â”€ [Anthropic's Computer Use implementation]
â”‚
â”œâ”€â”€ voice-layer/                    # Voice control additions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ wake_word.py               # Porcupine wake word detection
â”‚   â”œâ”€â”€ audio_capture.py           # Audio recording
â”‚   â”œâ”€â”€ transcription.py           # Whisper API integration
â”‚   â”œâ”€â”€ orchestrator.py            # Main coordination loop
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ config.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.yaml              # Configuration
â”‚   â””â”€â”€ wake_word.ppn              # Wake word model
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.voice           # Extended Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml         # Container orchestration
â”‚   â”œâ”€â”€ entrypoint.sh              # Container startup script
â”‚   â””â”€â”€ pulse-client.conf          # PulseAudio configuration
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ install.sh                 # Installation script
â”‚   â”œâ”€â”€ start.sh                   # Start services
â”‚   â”œâ”€â”€ stop.sh                    # Stop services
â”‚   â””â”€â”€ test_voice.sh              # Test voice pipeline
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_wake_word.py
    â”œâ”€â”€ test_audio.py
    â””â”€â”€ test_integration.py
```

## Configuration

Edit `config/settings.yaml`:

```yaml
wake_word:
  keyword: "ok computer"
  sensitivity: 0.5

audio:
  sample_rate: 16000
  record_seconds: 5
  silence_threshold: 500

api:
  anthropic_model: "claude-sonnet-4-20250514"
  whisper_model: "whisper-1"

computer_use:
  display_width: 1024
  display_height: 768
  max_steps: 50
```

## Development

### Setup Development Environment

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Lint code
flake8 voice-layer/
black voice-layer/
```

### Architecture Overview

Scrap AI Bot is built on three layers:

1. **Voice Layer** (this project) - Wake word, audio capture, transcription
2. **AI Layer** (Anthropic's Computer Use) - Vision, reasoning, tool execution
3. **System Layer** (Docker + X11) - Safe execution environment

See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed technical documentation.

### For AI Assistants

If you're an AI coding assistant working on this project, please read [AI_INSTRUCTIONS.md](AI_INSTRUCTIONS.md) for specific guidance on how components interact and coding standards.

## Roadmap

### Current Status: Alpha

- [x] Basic voice control integration
- [x] Wake word detection
- [x] Computer Use API integration
- [ ] Stable multi-step execution
- [ ] Error recovery
- [ ] Audio feedback (TTS)

### Planned Features

- [ ] Custom wake word training
- [ ] Task templates and macros
- [ ] Voice feedback with TTS
- [ ] Multi-language support
- [ ] Performance optimizations
- [ ] Mobile device control
- [ ] Plugin system

### Commercial Features (Future)

- Premium recommendation engine
- Team collaboration features
- Enterprise security and compliance
- Managed hosting service
- Priority support

## Security & Privacy

- **Local wake word detection** - No audio sent to cloud until activated
- **Sandboxed execution** - Runs in isolated Docker container
- **API key security** - Keys stored in environment variables only
- **Audit logging** - All actions logged for review

âš ï¸ **Warning**: This gives AI control over your computer. Review all actions and use in controlled environments only.

## Known Limitations

- Requires display (headless mode not yet supported)
- English language only (currently)
- High API costs for extended use
- Occasional misinterpretation of visual elements
- Requires stable internet connection

## Troubleshooting

### Wake word not detecting

```bash
# Test microphone
arecord -l

# Adjust sensitivity in config/settings.yaml
wake_word:
  sensitivity: 0.7  # Increase for better detection
```

### Computer Use actions failing

```bash
# Check Docker container logs
docker logs scrap-ai-bot

# Verify API keys
./scripts/test_voice.sh
```

### Audio quality issues

```bash
# Test audio capture
python -m voice-layer.audio_capture --test

# Check sample rate matches your microphone
pactl list sources
```

See [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) for more solutions.

## Contributing

We welcome contributions! Please read [CONTRIBUTING.md](CONTRIBUTING.md) before submitting PRs.

Key areas needing help:
- Error recovery and resilience
- Performance optimization
- Additional language support
- Documentation improvements

## License

This project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)**.

- âœ… Free for personal and non-commercial use
- âœ… Modifications must be open-sourced
- âœ… Network use triggers source disclosure
- ğŸ“§ Commercial licensing available - contact: andres@scrap-ai-bot.dev

See [LICENSE](LICENSE) for full text.

## Commercial Licensing

For commercial use cases that cannot comply with AGPL-3.0 (closed-source products, SaaS offerings, etc.), commercial licenses are available.

**Contact**: andres@scrap-ai-bot.dev

## Acknowledgments

Built on top of:
- [Anthropic's Computer Use Demo](https://github.com/anthropics/claude-quickstarts/tree/main/computer-use-demo)
- [Picovoice Porcupine](https://github.com/Picovoice/porcupine) for wake word detection
- [OpenAI Whisper](https://github.com/openai/whisper) for speech recognition

## Support

- ğŸ“– [Documentation](git@github.com:andresmascl/scrapbot.ai.git)
- ğŸ› [Issue Tracker](https://github.com/andresmascl/scrap-ai-bot/issues)
- ğŸ’¬ [Discussions](https://github.com/andresmascl/scrap-ai-bot/discussions)
- ğŸ“§ Email: support@scrap-ai-bot.dev

## Star History

If you find this project useful, please consider starring it on GitHub!

---

**Status**: Alpha - Not recommended for production use
